import os
import logging
import asyncio
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
import openai
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env
load_dotenv()
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –±–æ—Ç–∞ –∏ –¥–∏—Å–ø–µ—Ç—á–µ—Ä
bot = Bot(token=TOKEN)
dp = Dispatcher()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI
client = openai.OpenAI(api_key=OPENAI_API_KEY)

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã /start
@dp.message(Command("start"))
async def start_handler(message: types.Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –Ø –ì–∏–∫–ë–æ—Ç ü§ñ\n–ó–∞–¥–∞–≤–∞–π –º–Ω–µ –≤–æ–ø—Ä–æ—Å—ã –æ —Ç–µ—Ö–Ω–∏–∫–µ!")

# –û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Å–æ–æ–±—â–µ–Ω–∏–π
@dp.message()
async def chat_with_gpt(message: types.Message):
    try:
        response = client.chat.completions.create(  # ‚úÖ –ù–æ–≤—ã–π —Å–ø–æ—Å–æ–± –≤—ã–∑–æ–≤–∞ API
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": message.text}],
        )
        reply = response.choices[0].message.content
        await message.answer(reply)

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞: {e}")
        await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ OpenAI üò¢")

# –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞
async def main():
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
